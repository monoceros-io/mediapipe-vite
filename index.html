<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Image Segmenter with Pose Landmarker</title>
    <style>
        body {
            padding: 0;
            margin: 0;
        }
        .d-canv {
            border: 1px solid red;
        }
        video {
            position: absolute;
            top: 0;
        }
        canvas {
            position: absolute;
            top: 0;
            /* mix-blend-mode: color; */
        }
    </style>
</head>

<body>
    <video id="webcam" autoplay playsinline></video>
    <canvas class="d-canv" id="dump-canvas-0" width="640" height="480"></canvas>

    <script type="module">
        import { ImageSegmenter, FilesetResolver } from "./node_modules/@mediapipe/tasks-vision";
        import { PoseLandmarker, DrawingUtils } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

        let segmenter, poseLandmarker;
        const video = document.getElementById("webcam");
        const dumpCanvas = document.getElementById("dump-canvas-0");
        const dumpCtx = dumpCanvas.getContext("2d");
        const runningMode = "VIDEO";
        let frameCounter = 0; // Counter to track frames

        async function loadModels() {
            const vision = await FilesetResolver.forVisionTasks("./node_modules/@mediapipe/tasks-vision/wasm");

            // Load ImageSegmenter
            segmenter = await ImageSegmenter.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "./selfie_multiclass_256x256.tflite",
                    delegate: 'GPU'
                },
                runningMode: runningMode,
            });

            // Load PoseLandmarker
            poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,
                    delegate: "GPU"
                },
                runningMode: runningMode,
                numPoses: 1
            });

            console.log("Models loaded successfully.");
        }

        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    console.log("Webcam feed started.");
                    processVideoFrame();
                });
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        async function processVideoFrame() {
            if (!segmenter || !poseLandmarker) {
                console.error("Models not loaded.");
                return;
            }

            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext("2d");
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

            // Perform segmentation
            const segmentationResult = await segmenter.segmentForVideo(imageData, performance.now());
            if (segmentationResult && segmentationResult.confidenceMasks) {
                drawAllMasksToDumpCanvas(segmentationResult.confidenceMasks);
                segmentationResult.confidenceMasks.forEach(mask => mask.close()); // Free resources
            } else {
                console.warn("No segmentation result available.");
            }

            // Perform pose landmark detection every 5 frames
            if (frameCounter % 1 === 0) {
                poseLandmarker.detectForVideo(video, performance.now(), poseResult => {
                    drawPoseLandmarks(poseResult);
                });
            }

            frameCounter++; // Increment the frame counter
            requestAnimationFrame(processVideoFrame);
        }

        function drawAllMasksToDumpCanvas(confidenceMasks) {
            const { width, height } = confidenceMasks[0];
            if (dumpCanvas.width !== width || dumpCanvas.height !== height) {
                dumpCanvas.width = width;
                dumpCanvas.height = height;
            }

            const imageData = dumpCtx.createImageData(width, height);
            const data = imageData.data;

            // Define unique colors for each mask
            const colors = [
                [255, 0, 0],   // Red BACKGROUND
                [0, 255, 0],   // Green HAIR
                [0, 0, 255],   // Blue SKIN
                [255, 255, 0], // Yellow FACE
                [0, 255, 255], // Cyan CLOTHES
                [255, 0, 255]  // Magenta OBJECTS
            ];

            confidenceMasks.forEach((maskData, maskIndex) => {
                const maskArray = maskData.getAsFloat32Array();
                const [r, g, b] = colors[maskIndex % colors.length]; // Cycle through colors

                for (let i = 0; i < maskArray.length; i++) {
                    const alpha = maskArray[i] * 255; // Scale the float value to 0-255
                    const offset = i * 4;

                    // Blend the mask color with existing pixels
                    data[offset] = Math.max(data[offset], r * (alpha / 255)); // Red channel
                    data[offset + 1] = Math.max(data[offset + 1], g * (alpha / 255)); // Green channel
                    data[offset + 2] = Math.max(data[offset + 2], b * (alpha / 255)); // Blue channel
                    data[offset + 3] = 255; // Full opacity
                }
            });

            dumpCtx.putImageData(imageData, 0, 0);
        }

        function drawPoseLandmarks(poseResult) {
            const drawingUtils = new DrawingUtils(dumpCtx);

            // Draw pose landmarks on top of the segmentation data
            for (const landmark of poseResult.landmarks) {
                drawingUtils.drawLandmarks(landmark, {
                    radius: data => DrawingUtils.lerp(data.from.z, -0.15, 0.1, 5, 1)
                });
                drawingUtils.drawConnectors(landmark, PoseLandmarker.POSE_CONNECTIONS);
            }
        }

        loadModels();
        startWebcam();
    </script>
</body>

</html>
