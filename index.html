<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Image Segmenter</title>
</head>
<body>
    <h2>Webcam Feed for Segmentation</h2>
    <video id="webcam" autoplay playsinline></video>
    <br><br>
    <canvas id="canvas"></canvas>

    <script type="module">
        import { ImageSegmenter, FilesetResolver } from "./node_modules/@mediapipe/tasks-vision";

        let segmenter;
        const video = document.getElementById("webcam");

        async function loadSegmenter() {
            const vision = await FilesetResolver.forVisionTasks("./node_modules/@mediapipe/tasks-vision/wasm");

            segmenter = await ImageSegmenter.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "./selfie_multiclass_256x256.tflite"  // Ensure the correct path to your model
                },
                runningMode: "VIDEO",
            });

            console.log("Segmenter loaded successfully.");
        }

        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    console.log("Webcam feed started.");
                    processVideoFrame();
                });
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        async function processVideoFrame() {
            if (!segmenter) {
                console.error("Segmenter not loaded.");
                return;
            }

            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext("2d");
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const result = await segmenter.segmentForVideo(imageData, performance.now());

            if (result && result.confidenceMasks) {
                console.log("Segmentation result received:", result);
                drawMask(result.confidenceMasks);
            } else {
                console.warn("No segmentation result available.");
            }

            requestAnimationFrame(processVideoFrame);
        }

        function drawMask(confidenceMasks) {
            const canvas = document.getElementById("canvas");
            const ctx = canvas.getContext("2d");

            // Assuming all masks have the same dimensions
            const width = confidenceMasks[0].width;
            const height = confidenceMasks[0].height;
            canvas.width = width;
            canvas.height = height;


            const imageData = ctx.createImageData(width, height);

            // Combine all masks into a single alpha channel
            for (let i = 0; i < confidenceMasks.length; i++) {
                const maskData = confidenceMasks[i];
                console.log("Mask data:", maskData);
                for (let j = 0; j < maskData.length; j++) {
                    const alpha = maskData[j] * 255;
                    imageData.data[j * 4 + 3] = Math.max(imageData.data[j * 4 + 3], alpha); // Use the highest confidence
                }
            }

            ctx.putImageData(imageData, 0, 0);
        }

        loadSegmenter();
        startWebcam();
    </script>
</body>
</html>
