<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Image Segmenter</title>
    <style>
        .d-canv {
            border: 1px solid red;
        }

        #canvas {
            border: 1px solid blue;
            background-color: green;
        }
    </style>
</head>

<body>
    <h2>Webcam Feed for Segmentation</h2>
    <video id="webcam" autoplay playsinline></video>
    <br><br>
    <canvas id="canvas"></canvas>
    <canvas class="d-canv" id="dump-canvas-0" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-1" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-2" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-3" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-4" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-5" width="640" height="480"></canvas>

    <script type="module">
        import { ImageSegmenter, FilesetResolver } from "./node_modules/@mediapipe/tasks-vision";

        let segmenter;
        const video = document.getElementById("webcam");

        const dumpCanvases = [
            document.getElementById("dump-canvas-0"),
            document.getElementById("dump-canvas-1"),
            document.getElementById("dump-canvas-2"),
            document.getElementById("dump-canvas-3"),
            document.getElementById("dump-canvas-4"),
            document.getElementById("dump-canvas-5")
        ];

        async function loadSegmenter() {
            const vision = await FilesetResolver.forVisionTasks("./node_modules/@mediapipe/tasks-vision/wasm");

            segmenter = await ImageSegmenter.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "./selfie_multiclass_256x256.tflite",
                    delegate: 'GPU'
                },
                runningMode: "VIDEO",
            });

            console.log("Segmenter loaded successfully.");
        }

        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    console.log("Webcam feed started.");
                    processVideoFrame();
                });
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        async function processVideoFrame() {
            if (!segmenter) {
                console.error("Segmenter not loaded.");
                return;
            }

            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext("2d");
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

            const result = await segmenter.segmentForVideo(imageData, performance.now());

            if (result && result.confidenceMasks) {
                result.confidenceMasks.forEach((mask, index) => {
                    drawToDumpCanvas(mask, index); // Dump each mask to its canvas
                });

                // Free resources
                result.confidenceMasks.forEach(mask => mask.close());
            } else {
                console.warn("No segmentation result available.");
            }

            requestAnimationFrame(processVideoFrame);
        }

        function drawToDumpCanvas(maskData, index) {
            const dumpCanvas = dumpCanvases[index];
            if (!dumpCanvas) return;

            const ctx = dumpCanvas.getContext("2d");
            const { width, height } = maskData;

            if (dumpCanvas.width !== width || dumpCanvas.height !== height) {
                dumpCanvas.width = width;
                dumpCanvas.height = height;
            }

            const maskArray = maskData.getAsFloat32Array(); // Get the mask data as a Float32Array
            const imageData = ctx.createImageData(width, height);
            const data = imageData.data;

            for (let i = 0; i < maskArray.length; i++) {
                const alpha = maskArray[i] * 255; // Scale the float value to 0-255
                const offset = i * 4;
                data[offset] = alpha;    // Red channel for visualization
                data[offset + 1] = 0;    // Green channel
                data[offset + 2] = 0;    // Blue channel
                data[offset + 3] = 255;  // Full opacity
            }

            ctx.putImageData(imageData, 0, 0);
        }

        loadSegmenter();
        startWebcam();
    </script>
</body>

</html>
