<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Image Segmenter</title>
    <style>
        .d-canv {
            border: 1px solid red;
        }

        #canvas {
            border: 1px solid blue;
            background-color: green;
        }
    </style>
</head>
<body>
    <h2>Webcam Feed for Segmentation</h2>
    <video id="webcam" autoplay playsinline></video>
    <br><br>
    <canvas id="canvas"></canvas>
    <canvas class="d-canv" id="dump-canvas-0" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-1" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-2" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-3" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-4" width="640" height="480"></canvas>
    <canvas class="d-canv" id="dump-canvas-5" width="640" height="480"></canvas>

    <script type="module">
        import { ImageSegmenter, FilesetResolver } from "./node_modules/@mediapipe/tasks-vision";

        let segmenter;
        const video = document.getElementById("webcam");

        async function loadSegmenter() {
            const vision = await FilesetResolver.forVisionTasks("./node_modules/@mediapipe/tasks-vision/wasm");

            segmenter = await ImageSegmenter.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "./selfie_multiclass_256x256.tflite"  // Ensure the correct path to your model
                },
                runningMode: "VIDEO",
            });

            console.log("Segmenter loaded successfully.");
        }

        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    console.log("Webcam feed started.");
                    processVideoFrame();
                });
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        async function processVideoFrame() {
            if (!segmenter) {
                console.error("Segmenter not loaded.");
                return;
            }

            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext("2d");
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const result = await segmenter.segmentForVideo(imageData, performance.now());

            if (result && result.confidenceMasks) {
                result.confidenceMasks.forEach((mask, index) => {
                    
                    drawToDumpCanvas(mask, index); // Dump each mask to its canvas
                });
                drawMask(result.confidenceMasks[0]); // Visualize only the first mask for debugging
            } else {
                console.warn("No segmentation result available.");
            }

            requestAnimationFrame(processVideoFrame);
        }

        function drawMask(maskData) {
            const canvas = document.getElementById("canvas");
            const ctx = canvas.getContext("2d");

            const width = maskData.width;
            const height = maskData.height;
            canvas.width = width;
            canvas.height = height;

            console.log("Drawing mask with dimensions:", width, height);

            const imageData = ctx.createImageData(width, height);

            const maskArray = Array.from(maskData); // Ensure maskData is an array
            for (let i = 0; i < maskArray.length; i++) {
                const alpha = maskArray[i] * 255;
                imageData.data[i * 4] = 0;       // Red
                imageData.data[i * 4 + 1] = 0;   // Green
                imageData.data[i * 4 + 2] = 255; // Blue
                imageData.data[i * 4 + 3] = alpha; // Alpha
            }

            ctx.putImageData(imageData, 0, 0);
        }

        function drawToDumpCanvas(maskData, index) {
            const dumpCanvas = document.getElementById(`dump-canvas-${index}`);
            if (!dumpCanvas) return;

            const ctx = dumpCanvas.getContext("2d");
            const width = maskData.width;
            const height = maskData.height;
            dumpCanvas.width = width;
            dumpCanvas.height = height;

            const imageData = ctx.createImageData(width, height);
            const maskArray = maskData.g[0];

            for (let i = 0; i < maskArray.length; i++) {
                
                const alpha = maskArray[i] * 255;
                imageData.data[i * 4] = alpha;   // Red channel for visualization
                imageData.data[i * 4 + 1] = 0; // Green channel for visualization
                imageData.data[i * 4 + 2] = 0; // Blue channel for visualization
                imageData.data[i * 4 + 3] = 255;   // Full opacity
            }

            ctx.putImageData(imageData, 0, 0);
        }

        loadSegmenter();
        startWebcam();
    </script>
</body>
</html>
