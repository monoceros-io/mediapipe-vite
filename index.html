<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Selfie Segmentation</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background: #222;
        }
        .container {
            position: relative;
        }
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <video id="video" autoplay playsinline></video>
        <canvas id="output"></canvas>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
    <script>
      console.log("Loading MediaPipe Selfie Segmentation...");
        const video = document.getElementById('video');
        const canvas = document.getElementById('output');
        const ctx = canvas.getContext('2d');
        
        async function setupCamera() {
            try {
                console.log("Requesting camera access...");
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                await new Promise(resolve => video.onloadedmetadata = resolve);
                console.log("Camera access granted.");
            } catch (error) {
                console.error("Error accessing camera:", error);
            }
        }
        
        async function startSegmentation() {
            console.log("Starting segmentation...");
            await setupCamera();
            video.play();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            
            console.log("Initializing MediaPipe Selfie Segmentation...");
            const selfieSegmentation = new SelfieSegmentation({locateFile: (file) =>
                `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`
            });
            selfieSegmentation.setOptions({ modelSelection: 1 });
            await selfieSegmentation.initialize(); // Ensure WASM module is initialized
            selfieSegmentation.onResults(results => {
                ctx.save();
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height); // Draw the original video frame

                if (results.segmentationMask) {
                    // Draw the segmentation mask
                    ctx.globalCompositeOperation = 'destination-in';
                    ctx.drawImage(results.segmentationMask, 0, 0, canvas.width, canvas.height);

                    // Apply a semi-transparent green overlay
                    ctx.globalCompositeOperation = 'destination-over';
                    ctx.fillStyle = 'rgba(0, 255, 0, 0.5)';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                }

                ctx.restore();
            });

            function processFrame() {
              console.log("Processing frame...");
                selfieSegmentation.send({image: video}).catch(err => console.error("Error processing frame:", err));
                requestAnimationFrame(processFrame);
            }
            processFrame();
        }

        startSegmentation();
    </script>
</body>
</html>
